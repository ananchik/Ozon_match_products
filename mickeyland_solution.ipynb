{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf03c26-f837-4e2e-91b8-d079dbc211fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==1.4.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749184d5-f973-4b9f-a00d-f76b3c1f562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740c7b7-5938-4df8-a380-1ef4fbfa4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc5a8e-8349-482c-8138-c4111b8e1f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e61cb1-d0c7-45a8-bfb3-cb39caec8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8638ea-bba4-4ecb-81a1-21d4787285f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SetSimilaritySearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761eb22-0bb3-4315-9064-21612052ae95",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0546b-2e0c-4113-89ec-498b4b668d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from SetSimilaritySearch import all_pairs\n",
    "from Levenshtein import ratio\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import openai\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b101b-8541-4006-804c-2f4a8cb571c8",
   "metadata": {},
   "source": [
    "Подготовка данных с помощью следующих функций:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5fae2b-239d-44dc-8798-391b9228d36e",
   "metadata": {},
   "source": [
    "Функция блокировки входных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053de4e-f533-40a9-ac11-9017b0375dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocking_func() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Данная функция не участвует в действующем алгоритме, но является незаменимой \n",
    "    частью данного процесса - получение данных и сокращения их количетсва.\n",
    "    \n",
    "    Данная функция реализует следующий функцтонал:\n",
    "    1) Принимает данные из источника \n",
    "    2) Обрабатывает данные (приведение типов итд)\n",
    "    3) Отбирает актуальыные данные (current_date()-1)\n",
    "    4) Разделяет по количеству продукции (кол-во продукции > порогового значения)\n",
    "    5) Выбирает товар в наличие/нет (True/False) \n",
    "    6) Разделяет по категориям товара + подкатеории товара \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Данные из источника\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Dataframe() \n",
    "    (с данными по товарам определенного количества, категории и \n",
    "    актуальности)\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481af0a-9ef7-4d98-93ab-a127afed1522",
   "metadata": {},
   "source": [
    "Функция разметки разных тайтлов с помощью трансформера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257d98d-f16d-4b8f-b7e1-a56651f3a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_label(\n",
    "    df:pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Данная функция не участвует в действующем алгоритме, но является дополнительным инструментом,\n",
    "        который способен различать тайтлы товаров. На основе данной функции можно реализовать свой трансформер,\n",
    "        следуя архитектуре, например, chatgpt, который в дальнейшем спообен внести дополнительную фичу различия товаров по их тайтлам\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df : pd.Dataframe() - датафрейм с дополнительной фичей в качестве разметки с помощью трансформера (например, chatgpt)\n",
    "    \"\"\"\n",
    "    openai.api_key = \"sk-???\"\n",
    "    \n",
    "    title_1 = \"Колодка TDM Electric четырехместная без заземл\"\n",
    "    title_2 = \"Клавиатура черная с черной рамкой для 25-011879\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "              {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
    "              {\"role\": \"user\", \"content\": f\"{title_1} and {title_2} are similar? Yes or No?\"},\n",
    "          ]\n",
    "    )\n",
    "\n",
    "    result = ''\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "\n",
    "    df[\"gpt_label\"] = result\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f218b0c-43d8-4dba-811e-2bbbd4c09cc7",
   "metadata": {},
   "source": [
    "Блок функции-извлекателей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74160380-c903-4d7f-b969-5cb38eb0e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category_3lvl(\n",
    "    df:pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Данная функция является извлекателем категории на уровне равном 3 из исходного датафрейма\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        df : {pandas.DataFrame} датафрейм с дополнительной фичой - category_3lvl\n",
    "    \"\"\"\n",
    "\n",
    "    categories_arr = []\n",
    "    for i, _ in enumerate(df[\"categories\"]):\n",
    "        try:\n",
    "            categories_arr.append(json.loads(df['categories'][i])['3']) \n",
    "        except:\n",
    "            categories_arr.append(\"\")\n",
    "      \n",
    "    df[\"category_3lvl\"] = categories_arr\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7baba4-5a38-469a-b50e-e8ee2f8f3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brand(\n",
    "    df:pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Данная функция является извлекателем бренда из исходного датафрейма\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        df : {pandas.DataFrame} датафрейм с дополнительной фичой - brand\n",
    "    \"\"\"\n",
    "\n",
    "    brand_arr = []\n",
    "    for i, _ in enumerate(df[\"characteristic_attributes_mapping\"]):\n",
    "        try:\n",
    "            brand_arr.append(json.loads(df['characteristic_attributes_mapping'][i])['Бренд'][0]) \n",
    "        except:\n",
    "            brand_arr.append(\"\")\n",
    "\n",
    "    df[\"brand\"] = brand_arr\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82049847-d3d6-4b65-ad37-61baecf79d70",
   "metadata": {},
   "source": [
    "Функция сопоставления id и их данных попарно "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3a2fa-a3e5-4b8c-b0c3-9b81399e5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_products(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "       Данная функция сопоставляет id продуктов их дополнительные атрибуты согласно \n",
    "       данным из файла с парами\n",
    "       \n",
    "       Parameters\n",
    "       ----------\n",
    "       df : {pandas.DataFrame}\n",
    "        \n",
    "       Returns\n",
    "       ----------\n",
    "       df : {pandas.DataFrame} датафрейм попарно соединенный согласно файлу с парами\n",
    "       \n",
    "    \"\"\"\n",
    "\n",
    "    pairs_df = pd.read_parquet(\"train_pairs.parquet\") # train_pairs\n",
    "    pairs_df = pairs_df[[\"variantid1\", \"variantid2\", \"target\"]] # , \"target\"\n",
    "\n",
    "    df_ready = pd.DataFrame()\n",
    "    for i in range(len(pairs_df)): # DELETE .iloc[:20]\n",
    "        # print(\"i -\", i)\n",
    "        prod_ind_arr = pairs_df.iloc[i, 0:2].to_list() # [52076340,290590137]      # non actual/change columns (.iloc[i, 1:] - for train / .iloc[i, 0:] - for test)\n",
    "        # print(prod_ind_arr)\n",
    "\n",
    "        if df[df[\"variantid\"] == int(prod_ind_arr[0])].empty == False: # df[df[\"variantid\"] == 52076340] \n",
    "            df_id1 = df[df[\"variantid\"] == prod_ind_arr[0]] \\\n",
    "                    .reset_index() \\\n",
    "                    .rename(columns={\n",
    "                        \"index\": \"index1\",\n",
    "                        \"variantid\": \"variantid1\", \n",
    "                        \"name\": \"name1\", \n",
    "                        \"categories\": \"categories1\",\n",
    "                        \"color_parsed\":\"color_parsed1\",\n",
    "                        \"pic_embeddings_resnet_v1\": \"pic_embeddings_resnet_v1_1\", \n",
    "                        \"main_pic_embeddings_resnet_v1\": \"main_pic_embeddings_resnet_v1_1\",\n",
    "                        \"name_bert_64\": \"name_bert_64_1\",\n",
    "                        \"characteristic_attributes_mapping\": \"characteristic_attributes_mapping1\",\n",
    "                        \"brand\": \"brand1\",\n",
    "                        \"category_3lvl\": \"category_3lvl_1\"\n",
    "                        }) \n",
    "        else:\n",
    "            df_id1 = pd.DataFrame()\n",
    "\n",
    "        if df[df[\"variantid\"] == int(prod_ind_arr[1])].empty == False: # df[df[\"variantid\"] == 290590137] \n",
    "            df_id2 = df[df[\"variantid\"] == prod_ind_arr[1]] \\\n",
    "                    .reset_index() \\\n",
    "                    .rename(columns={\n",
    "                        \"index\": \"index2\",\n",
    "                        \"variantid\": \"variantid2\", \n",
    "                        \"name\": \"name2\", \n",
    "                        \"categories\": \"categories2\",\n",
    "                        \"color_parsed\":\"color_parsed2\",\n",
    "                        \"pic_embeddings_resnet_v1\": \"pic_embeddings_resnet_v1_2\", \n",
    "                        \"main_pic_embeddings_resnet_v1\": \"main_pic_embeddings_resnet_v1_2\",\n",
    "                        \"name_bert_64\": \"name_bert_64_2\",\n",
    "                        \"characteristic_attributes_mapping\": \"characteristic_attributes_mapping2\",\n",
    "                        \"brand\": \"brand2\",\n",
    "                        \"category_3lvl\": \"category_3lvl_2\"\n",
    "                        }) \n",
    "        else:\n",
    "            df_id2 = pd.DataFrame()\n",
    "\n",
    "        df_id1_id2 = pd.concat([df_id1, df_id2], axis=1)\n",
    "\n",
    "        df_ready = pd.concat([df_ready, df_id1_id2], axis=0)\n",
    "\n",
    "    return df_ready.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dcf9ca-07f3-4638-a2b5-acd59e074dab",
   "metadata": {},
   "source": [
    "Функции сходства данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c57e8-0307-4655-a456-af38e3bc1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity_num(\n",
    "    df:pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    # Vectors input\n",
    "    \"\"\"\n",
    "        Данная функция предназначена для расчета косинусной схожести объектов \n",
    "        для числовых векторов\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        df : {pandas.DataFrame} датафрейм с дополнительными фичами схожести \n",
    "        числовых векторов - [\"cos_sim_pic_emb\", \"cos_sim_main_pic_emb\", \"cos_sim_name_bert\"]\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    columns = [(\"pic_embeddings_resnet_v1_1\", \"pic_embeddings_resnet_v1_2\"),\n",
    "             (\"main_pic_embeddings_resnet_v1_1\", \"main_pic_embeddings_resnet_v1_2\"),\n",
    "             (\"name_bert_64_1\", \"name_bert_64_2\") \n",
    "             ]\n",
    "    new_col = [\"cos_sim_pic_emb\", \"cos_sim_main_pic_emb\", \"cos_sim_name_bert\"]\n",
    "  \n",
    "    for i, k in enumerate(columns):\n",
    "        cos_sim_arr = []\n",
    "        for j in range(len(df)):\n",
    "            try:\n",
    "                col_1 = k[0]\n",
    "                col_2 = k[1]\n",
    "                cos_sim_arr.append(\n",
    "                    np.dot(tst_df[col_1][j][0], tst_df[col_2][j][0]) / (norm(tst_df[col_1][j][0]) * norm(tst_df[col_2][j][0]))\n",
    "                )\n",
    "            except:\n",
    "                cos_sim_arr.append(0)\n",
    "\n",
    "        df[new_col[i]] = cos_sim_arr\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdc794-2ff4-40c1-a9cc-60053e342212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_similarity(\n",
    "    df:pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    # Words input\n",
    "    \"\"\"\n",
    "        Данная функция предназначена для расчета расстояния Левинштейна схожести объектов \n",
    "        для текстовых атрибутов\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        df : {pandas.DataFrame} датафрейм с дополнительными фичами схожести \n",
    "        текстовых атрибутов - [\"levenshtein_sim_brand\", \"levenshtein_sim_category_3lvl\", \"levenshtein_sim_name\"]\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    columns = [\n",
    "      (\"brand1\", \"brand2\"),\n",
    "      (\"category_3lvl_1\", \"category_3lvl_2\"),\n",
    "      (\"name1\", \"name2\")\n",
    "    ]\n",
    "    new_col = [\"levenshtein_sim_brand\", \"levenshtein_sim_category_3lvl\", \"levenshtein_sim_name\"]\n",
    "\n",
    "    for i, k in enumerate(columns):\n",
    "        levenshtein_sim_arr = []\n",
    "        col_1 = k[0]\n",
    "        col_2 = k[1]\n",
    "        for ind, val in zip(df[col_1].to_list(), df[col_2].to_list()):\n",
    "            try:\n",
    "                levenshtein_sim_arr.append(\n",
    "                    ratio(ind, val)\n",
    "                )\n",
    "            except:\n",
    "                levenshtein_sim_arr.append(0)\n",
    "\n",
    "        df[new_col[i]] = levenshtein_sim_arr\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829e30d-1343-47c5-99db-f5cd7dcec597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Данная функция предназначена для расчета расстояния Джаккарта схожести объектов \n",
    "        для текстовых атрибутов\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        df : {pandas.DataFrame} датафрейм с дополнительными фичами схожести \n",
    "        текстовых атрибутов - [\"jaccard_sim_brand\", \"jaccard_sim_category_3lvl\", \"jaccard_sim_name\"]\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    columns = [\n",
    "      (\"brand1\", \"brand2\"),\n",
    "      (\"category_3lvl_1\", \"category_3lvl_2\"),\n",
    "      (\"name1\", \"name2\")\n",
    "  ]\n",
    "    new_col = [\"jaccard_sim_brand\", \"jaccard_sim_category_3lvl\", \"jaccard_sim_name\"]\n",
    "  \n",
    "    for i, k in enumerate(columns):\n",
    "        jacc_sim_arr = []\n",
    "        col_1 = k[0]\n",
    "        col_2 = k[1]\n",
    "        for j in range(len(df)):\n",
    "            try:\n",
    "                doc1 = df[col_1][j]\n",
    "                doc2 = df[col_2][j]\n",
    "\n",
    "                words_doc1 = set(doc1.lower().split()) \n",
    "                words_doc2 = set(doc2.lower().split())\n",
    "\n",
    "                intersection = words_doc1.intersection(words_doc2)\n",
    "                union = words_doc1.union(words_doc2)\n",
    "\n",
    "                jacc_sim_arr.append(float(len(intersection)) / len(union))\n",
    "            except:\n",
    "                jacc_sim_arr.append(0)\n",
    "\n",
    "        df[new_col[i]] = jacc_sim_arr\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc221e02-8e47-491e-b6e6-b20fed416b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containment_similarity(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Данная функция предназначена для расчета расстояния по содержанию схожести объектов \n",
    "        для текстовых атрибутов\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        df : {pandas.DataFrame} датафрейм с дополнительными фичами схожести \n",
    "        текстовых атрибутов - [\"containment_sim_brand\", \"containment_sim_category_3lvl\", \"containment_sim_name\"]\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    columns = [\n",
    "      (\"brand1\", \"brand2\"),\n",
    "      (\"category_3lvl_1\", \"category_3lvl_2\"),\n",
    "      (\"name1\", \"name2\")\n",
    "      ]\n",
    "    new_col = [\"containment_sim_brand\", \"containment_sim_category_3lvl\", \"containment_sim_name\"]\n",
    "  \n",
    "    for i, k in enumerate(columns):\n",
    "        containment_sim_arr = []\n",
    "        col_1 = k[0]\n",
    "        col_2 = k[1]\n",
    "        for j in range(len(df)):\n",
    "            try:\n",
    "                doc1 = df[col_1][j]\n",
    "                doc2 = df[col_2][j]\n",
    "\n",
    "                words_doc1 = set(doc1.lower().split()) \n",
    "                words_doc2 = set(doc2.lower().split())\n",
    "\n",
    "                intersection = words_doc1.intersection(words_doc2)\n",
    "\n",
    "                if len(words_doc1) > len(words_doc2):\n",
    "                    first_set = len(words_doc1)\n",
    "                else:\n",
    "                    first_set = len(words_doc2)\n",
    "\n",
    "                containment_sim_arr.append(float(len(intersection)) / first_set)\n",
    "            except:\n",
    "                containment_sim_arr.append(0)\n",
    "\n",
    "        df[new_col[i]] = containment_sim_arr\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e21647-7945-4d0d-9b30-4447f9e2ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim(*strs): \n",
    "    vectors = [t for t in get_vectors(*strs)]\n",
    "    return cosine_similarity(vectors)\n",
    "    \n",
    "def get_vectors(*strs):\n",
    "    text = [t for t in strs]\n",
    "    # print(text)\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(text)\n",
    "    return vectorizer.transform(text).toarray()\n",
    "\n",
    "def tf_idf_cos_similarity(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Данная функция предназначена для расчета косинусной схожести объектов \n",
    "        для текстовых атрибутов на основе tf-idf\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : {pandas.DataFrame}\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        df : {pandas.DataFrame} датафрейм с дополнительными фичами схожести \n",
    "        текстовых атрибутов - [\"tf_idf_cos_sim_name\", \"tf_idf_cos_sim_category_3lvl\"]\n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    columns = [\n",
    "      (\"name1\", \"name2\"),\n",
    "      (\"category_3lvl_1\", \"category_3lvl_2\")\n",
    "      ]\n",
    "    new_col = [\"tf_idf_cos_sim_name\", \"tf_idf_cos_sim_category_3lvl\"]\n",
    "\n",
    "    for i, k in enumerate(columns):\n",
    "        tf_idf_cos_sim_arr = []\n",
    "        col_1 = k[0]\n",
    "        col_2 = k[1]\n",
    "        for j in range(len(df)):\n",
    "            try:\n",
    "                tf_idf_cos_sim_arr.append(get_cosine_sim(df[col_1][j], df[col_2][j])[0][1])\n",
    "            except:\n",
    "                tf_idf_cos_sim_arr.append(0)\n",
    "    \n",
    "        df[new_col[i]] = tf_idf_cos_sim_arr\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb149f5-78ad-4372-8260-c58825253554",
   "metadata": {},
   "source": [
    "PipeLine Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98376618-1d65-4190-a246-9cf68ef0a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"train_data.parquet\") # test_data - так как данных тут меньше (для отладки функций)/ нужно train_data.parquet\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2a289-83e1-474e-9d1c-c82e842e0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df = pd.read_parquet(\"train_pairs.parquet\")\n",
    "pairs_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c50e4c-58fd-410d-a43e-148d0efb52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df = extract_category_3lvl(train_df)\n",
    "tst_df = extract_brand(tst_df)\n",
    "tst_df = match_products(tst_df)\n",
    "tst_df = cos_similarity_num(tst_df)\n",
    "tst_df = levenshtein_similarity(tst_df)\n",
    "tst_df = jaccard_similarity(tst_df)\n",
    "tst_df = containment_similarity(tst_df)\n",
    "tst_df = tf_idf_cos_similarity(tst_df)\n",
    "\n",
    "tst_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b85a14f-d40d-41c3-8d26-8a852490d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df[\"target\"] = pairs_df[\"target\"]\n",
    "tst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60d4ed-acc5-4751-b95a-4737f6348459",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['color_parsed1'].fillna(\"['бесцветный']\",inplace = True)\n",
    "tst_df['color_parsed2'].fillna(\"['бесцветный']\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdba80f-4018-4527-82bb-07772c9a7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выборка фичей \n",
    "\n",
    "columns_need = [\n",
    "    'variantid1','variantid2', \n",
    "    'name1','name2', \n",
    "    'color_parsed1','color_parsed2',\n",
    "#     'pic_embeddings_resnet_v1_1', 'pic_embeddings_resnet_v1_2',\n",
    "    'main_pic_embeddings_resnet_v1_1', 'main_pic_embeddings_resnet_v1_2',\n",
    "    'name_bert_64_1', 'name_bert_64_2',\n",
    "    'category_3lvl_1','category_3lvl_2',\n",
    "#     'brand1','brand2',\n",
    "    'cos_sim_pic_emb', 'cos_sim_main_pic_emb', 'cos_sim_name_bert',\n",
    "    'levenshtein_sim_brand', 'levenshtein_sim_category_3lvl',\n",
    "    'levenshtein_sim_name', 'jaccard_sim_brand',\n",
    "    'jaccard_sim_category_3lvl', 'jaccard_sim_name',\n",
    "    'containment_sim_brand', 'containment_sim_category_3lvl',\n",
    "    'containment_sim_name', 'tf_idf_cos_sim_name',\n",
    "    'tf_idf_cos_sim_category_3lvl', \n",
    "    'target'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56984e32-99c7-4478-aede-3029f41646d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_df = tst_df[columns_need]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27b169-219d-4b65-8de8-9d2943d5dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mid_df.iloc[:, 2: mid_df.shape[1]-1]\n",
    "y = mid_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ef84a-03b6-470e-ac15-737b4d24865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "def get_categorical_indicies(X):\n",
    "    \"\"\"\n",
    "        Данная функция реализует поиск индексов, которые считаются типом \"object\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : датафрейм с фичами, на которых в дальнейшем будет обучаться модель\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        cat_indicies : список индексов, которые считаются типом \"object\"\n",
    "        \n",
    "    \"\"\"\n",
    "    cats = []\n",
    "    for col in X.columns:\n",
    "        if is_numeric_dtype(X[col]):\n",
    "            pass\n",
    "        else:\n",
    "            cats.append(col)\n",
    "    cat_indicies = []\n",
    "    for col in cats:\n",
    "        cat_indicies.append(X.columns.get_loc(col))\n",
    "        \n",
    "    return cat_indicies\n",
    "\n",
    "categorical_indicies = get_categorical_indicies(X)\n",
    "categorical_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52df9b-0db6-460e-8990-707eef396df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cats(X):\n",
    "    \"\"\"\n",
    "        Данная функция реализует конвертацию признаков \"object\" -> \"category\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : датафрейм с фичами, на которых в дальнейшем будет обучаться модель\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        -\n",
    "    \"\"\"\n",
    "    cats = []\n",
    "    for col in X.columns:\n",
    "        if is_numeric_dtype(X[col]):\n",
    "            pass\n",
    "        else:\n",
    "            cats.append(col)\n",
    "    cat_indicies = []\n",
    "    for col in cats:\n",
    "        X[col] = X[col].astype('category')\n",
    "        \n",
    "convert_cats(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572a9b4-93f1-49aa-86b2-c8d0e04b1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42582243-312f-4a57-a940-23579526ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_changed.csv - файл, который содержит пары товаров с их дополнительными\n",
    "# атрибутами (реализация аналогична для train_data.parquet, только с даннами из test_data.parquet)\n",
    "df_test = pd.read_csv(\"full_test_data_changed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf54ae-ebdf-4dea-8fbe-8ce50fdeb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_need_test = [\n",
    "    'variantid1','variantid2', \n",
    "    'name1','name2', \n",
    "    'color_parsed1','color_parsed2',\n",
    "#     'pic_embeddings_resnet_v1_1', 'pic_embeddings_resnet_v1_2',\n",
    "    'main_pic_embeddings_resnet_v1_1', 'main_pic_embeddings_resnet_v1_2',\n",
    "    'name_bert_64_1', 'name_bert_64_2',\n",
    "    'category_3lvl_1','category_3lvl_2',\n",
    "#     'brand1','brand2',\n",
    "    'cos_sim_pic_emb', 'cos_sim_main_pic_emb', 'cos_sim_name_bert',\n",
    "    'levenshtein_sim_brand', 'levenshtein_sim_category_3lvl',\n",
    "    'levenshtein_sim_name', 'jaccard_sim_brand',\n",
    "    'jaccard_sim_category_3lvl', 'jaccard_sim_name',\n",
    "    'containment_sim_brand', 'containment_sim_category_3lvl',\n",
    "    'containment_sim_name', 'tf_idf_cos_sim_name',\n",
    "    'tf_idf_cos_sim_category_3lvl', \n",
    "] \n",
    "\n",
    "X_test_start = df_test[columns_need_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a4b3b-5b53-43df-beb4-4eb4c0a1f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_start['color_parsed1'].fillna(\"['бесцветный']\",inplace = True)\n",
    "X_test_start['color_parsed2'].fillna(\"['бесцветный']\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9ec2d-70b0-40ca-a17c-11ccaacdc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_start.iloc[:, 2:]\n",
    "\n",
    "convert_cats(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b5426-72f5-4dbb-b828-36931d283c0d",
   "metadata": {},
   "source": [
    "ML модель "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc5e81-7680-4e11-861b-226bd8ccd7c0",
   "metadata": {},
   "source": [
    "Поиск оптимальных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df9e08-7f05-4242-b6b0-a6341612787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_catboost = Pipeline([\n",
    "    ('scl', StandardScaler()),\n",
    "    ('clf', CatBoostClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "# model = CatBoostClassifier()\n",
    "# param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "grid = {'clf__learning_rate': [ 0.03, 0.01, 0.1, 1.0],\n",
    "        'clf__depth': [4, 6, 10],\n",
    "        'clf__l2_leaf_reg': [2,  5, 7, 9]}\n",
    "\n",
    "gs_catboost = GridSearchCV(estimator=pipe_catboost,\n",
    "                           param_grid=grid,\n",
    "                           cv=10, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "gs_catboost.fit(X_train.iloc[:5000], y_train.iloc[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5b787-3c6e-443b-ab3f-c60d60c4fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",gs_catboost.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",gs_catboost.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",gs_catboost.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35743ec6-2a57-44c2-94fd-19ec32a9f71b",
   "metadata": {},
   "source": [
    "Реализация ML модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a33f8-46f8-40a8-963c-2898b6babaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_catboost_v2 = CatBoostClassifier(random_state=1,\n",
    "                                  loss_function='Logloss',\n",
    "                                  # eval_metric='Accuracy',\n",
    "                                  depth=7, \n",
    "                                  l2_leaf_reg=5, \n",
    "                                  learning_rate=0.1 # 0.05\n",
    "                                 )\n",
    "cls_catboost_v2.fit(X_train,y_train,\n",
    "                 cat_features=categorical_indicies,\n",
    "                 eval_set=(X_val, y_val)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6064ce-9a43-4d56-9e0d-4d1219be5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v2 = cls_catboost_v2.predict_proba(X_test)\n",
    "predictions_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d26581-afbd-4943-80c0-8be6a8f045d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_full[\"target\"] = predictions_v2[:,1]\n",
    "\n",
    "prepared_df_catboost_v2 = df_test_full[[\"variantid1\", \"variantid2\", \"target\"]]\n",
    "prepared_df_catboost_v2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f854b9d-3869-4f3d-ab2f-f60b777c7a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df_catboost_v2.to_csv(\"catboost_prepared_dataset_v2.csv\", \n",
    "                               index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
